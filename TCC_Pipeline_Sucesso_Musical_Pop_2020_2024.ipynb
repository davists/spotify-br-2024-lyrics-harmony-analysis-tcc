{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ea8a97",
   "metadata": {},
   "source": [
    "\n",
    "# TCC – Predição do Sucesso Musical (Pop, Spotify 2020–2024)\n",
    "\n",
    "Notebook de referência para **coleta, processamento, modelagem e exportação de resultados** do TCC do MBA USP/ESALQ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca711e1",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Ambiente e dependências\n",
    "\n",
    "Execute esta célula para importar bibliotecas. Se necessário, descomente os comandos `pip`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e63235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "!pip install pandas numpy matplotlib scikit-learn tqdm python-dotenv\n",
    "!pip install spotipy lyricsgenius librosa music21 xgboost --upgrade\n",
    "!pip install beautifulsoup4 requests --quiet\n",
    "!pip install spotipy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa3626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente carregado. HAS_XGB = True\n"
     ]
    }
   ],
   "source": [
    "# Collecting Historical TOP 50 Streaming Data from Pro-Música Brasil\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "def fetch_pro_musica_data(period='04/2024'):\n",
    "    \"\"\"Fetch TOP 50 streaming data from Pro-Música Brasil with proper session handling\"\"\"\n",
    "    \n",
    "    # Create session for connection reuse\n",
    "    session = requests.Session()\n",
    "    \n",
    "    url = f'https://pro-musicabr.org.br/home/top-50-streaming/?top50sPeriodo={period}'\n",
    "    \n",
    "    # Set headers exactly matching the curl command\n",
    "    session.headers.update({\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,es;q=0.8,pt;q=0.7,fr;q=0.6',\n",
    "        'Priority': 'u=0, i',\n",
    "        'Referer': 'https://pro-musicabr.org.br/home/top-50-streaming/?top50sPeriodo=06/2024',\n",
    "        'Sec-CH-UA': '\"Not;A=Brand\";v=\"99\", \"Google Chrome\";v=\"139\", \"Chromium\";v=\"139\"',\n",
    "        'Sec-CH-UA-Mobile': '?0',\n",
    "        'Sec-CH-UA-Platform': '\"Windows\"',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # Add cookies to maintain session\n",
    "    session.cookies.update({\n",
    "        '_ga': 'GA1.1.1144301064.1757204721',\n",
    "        '_ga_BGET1L6V9K': 'GS2.1.s1757204720$o1$g1$t1757204994$j25$l0$h209261057',\n",
    "        'cookieconsent_status': 'dismiss'\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        # Add delay to be respectful to the server\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Make the request with timeout and allow redirects\n",
    "        response = session.get(url, timeout=30, allow_redirects=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print(f\"Request URL: {response.url}\")\n",
    "        print(f\"Response Status Code: {response.status_code}\")\n",
    "        print(f\"Response Content Length: {len(response.content)} bytes\")\n",
    "\n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Look for the streaming data table\n",
    "        table = soup.find('table', class_='table table-top-streams')\n",
    "        \n",
    "        if table:\n",
    "            # Extract data from table rows\n",
    "            rows = []\n",
    "            tbody = table.find('tbody')\n",
    "            \n",
    "            if tbody:\n",
    "                for tr in tbody.find_all('tr'):\n",
    "                    cells = tr.find_all('td')\n",
    "                    if len(cells) >= 6:\n",
    "                        # Extract position\n",
    "                        position = cells[1].get_text(strip=True)\n",
    "                        \n",
    "                        # Extract title and artist from the combined cell\n",
    "                        title_artist_cell = cells[3]\n",
    "                        text_content = title_artist_cell.get_text(separator='|', strip=True)\n",
    "                        \n",
    "                        # Split by | to separate title and artist\n",
    "                        parts = text_content.split('|')\n",
    "                        if len(parts) >= 2:\n",
    "                            title = parts[0].strip()\n",
    "                            artist = parts[1].strip()\n",
    "                        else:\n",
    "                            title = parts[0].strip()\n",
    "                            artist = \"\"\n",
    "                        \n",
    "                        # Extract record label and distributor\n",
    "                        gravadora = cells[4].get_text(strip=True)\n",
    "                        distribuidora = cells[5].get_text(strip=True)\n",
    "                        \n",
    "                        rows.append({\n",
    "                            'posicao': position,\n",
    "                            'titulo': title,\n",
    "                            'artista': artist,\n",
    "                            'gravadora': gravadora,\n",
    "                            'distribuidora': distribuidora\n",
    "                        })\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df_top50 = pd.DataFrame(rows)\n",
    "            return df_top50\n",
    "        else:\n",
    "            print(\"Table with class 'table table-top-streams' not found\")\n",
    "            # Try alternative table parsing\n",
    "            tables = soup.find_all('table')\n",
    "            if tables:\n",
    "                print(f\"Found {len(tables)} tables, trying first one...\")\n",
    "                return pd.read_html(str(tables[0]))[0]\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "def collect_historical_data(start_year=2022, start_month=1, end_year=2024, end_month=12):\n",
    "    \"\"\"\n",
    "    Collect TOP 50 streaming data from Pro-Música Brasil for multiple periods\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    failed_periods = []\n",
    "    \n",
    "    # Generate all periods from start to end\n",
    "    current_year = start_year\n",
    "    current_month = start_month\n",
    "    \n",
    "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month):\n",
    "        period = f\"{current_month:02d}/{current_year}\"\n",
    "        print(f\"\\n=== Collecting data for {period} ===\")\n",
    "        \n",
    "        try:\n",
    "            # Fetch data for this period\n",
    "            df_period = fetch_pro_musica_data(period)\n",
    "            \n",
    "            if not df_period.empty:\n",
    "                # Add period information to the dataframe\n",
    "                df_period['periodo'] = period\n",
    "                df_period['ano'] = current_year\n",
    "                df_period['mes'] = current_month\n",
    "                all_data.append(df_period)\n",
    "                print(f\"✅ Successfully collected {len(df_period)} tracks for {period}\")\n",
    "            else:\n",
    "                print(f\"❌ No data found for {period}\")\n",
    "                failed_periods.append(period)\n",
    "            \n",
    "            # Be respectful to the server - wait between requests\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error collecting data for {period}: {e}\")\n",
    "            failed_periods.append(period)\n",
    "            time.sleep(5)  # Wait longer on error\n",
    "        \n",
    "        # Move to next month\n",
    "        current_month += 1\n",
    "        if current_month > 12:\n",
    "            current_month = 1\n",
    "            current_year += 1\n",
    "    \n",
    "    # Combine all data\n",
    "    if all_data:\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\n=== Collection Summary ===\")\n",
    "        print(f\"Total periods processed: {len(all_data) + len(failed_periods)}\")\n",
    "        print(f\"Successful collections: {len(all_data)}\")\n",
    "        print(f\"Failed collections: {len(failed_periods)}\")\n",
    "        if failed_periods:\n",
    "            print(f\"Failed periods: {', '.join(failed_periods)}\")\n",
    "        print(f\"Total tracks collected: {len(df_combined)}\")\n",
    "        return df_combined, failed_periods\n",
    "    else:\n",
    "        print(\"❌ No data was collected from any period\")\n",
    "        return pd.DataFrame(), failed_periods\n",
    "\n",
    "def save_data_with_timestamp(df, base_filename=\"pro_musica_top50_historical\"):\n",
    "    \"\"\"\n",
    "    Save the dataframe with timestamp and create backup\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to save\")\n",
    "        return None\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    data_dir = Path('./data')\n",
    "    data_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{base_filename}_{timestamp}.csv\"\n",
    "    filepath = data_dir / filename\n",
    "    \n",
    "    # Save the data\n",
    "    df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "    print(f\"✅ Data saved to: {filepath}\")\n",
    "    \n",
    "    # Also save a copy without timestamp for easy access\n",
    "    latest_filepath = data_dir / f\"{base_filename}_latest.csv\"\n",
    "    df.to_csv(latest_filepath, index=False, encoding='utf-8')\n",
    "    print(f\"✅ Latest copy saved to: {latest_filepath}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\n=== Data Summary ===\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Periods covered: {df['periodo'].nunique()}\")\n",
    "    print(f\"Date range: {df['periodo'].min()} to {df['periodo'].max()}\")\n",
    "    print(f\"Unique tracks: {df['titulo'].nunique()}\")\n",
    "    print(f\"Unique artists: {df['artista'].nunique()}\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# Execute the data collection\n",
    "print(\"Starting historical data collection from Pro-Música Brasil...\")\n",
    "print(\"This will collect TOP 50 data from 01/2022 to 12/2024\")\n",
    "print(\"Please be patient as this will take several minutes...\")\n",
    "\n",
    "# Collect the data\n",
    "df_historical, failed_periods = collect_historical_data(\n",
    "    start_year=2019, start_month=1,\n",
    "    end_year=2024, end_month=12\n",
    ")\n",
    "\n",
    "# Save the data if we got any\n",
    "if not df_historical.empty:\n",
    "    filepath = save_data_with_timestamp(df_historical)\n",
    "    \n",
    "    # Display sample of the data\n",
    "    print(f\"\\n=== Sample of collected data ===\")\n",
    "    print(df_historical.head(10))\n",
    "    \n",
    "    # Show data by period\n",
    "    period_summary = df_historical.groupby('periodo').agg({\n",
    "        'titulo': 'count',\n",
    "        'artista': 'nunique'\n",
    "    }).rename(columns={'titulo': 'tracks', 'artista': 'unique_artists'})\n",
    "    print(f\"\\n=== Data by period ===\")\n",
    "    print(period_summary)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No data was collected. Please check the website availability and try again.\")\n",
    "\n",
    "print(\"\\n=== Collection Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load song attributes from spotify API\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Authenticate with your credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "    client_id=\"YOUR_CLIENT_ID\",\n",
    "    client_secret=\"YOUR_CLIENT_SECRET\"\n",
    "))\n",
    "\n",
    "# Search for a specific track\n",
    "results = sp.search(q='track:Seven Nation Army artist:The White Stripes', limit=1)\n",
    "track_id = results['tracks']['items'][0]['id']\n",
    "\n",
    "# Get the audio features for that track\n",
    "features = sp.audio_features(track_id)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef48ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente carregado. HAS_XGB = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Modelos adicionais (opcional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    HAS_XGB = False\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Diretório de exportação\n",
    "EXPORT_DIR = Path('./exports')\n",
    "EXPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print('Ambiente carregado. HAS_XGB =', HAS_XGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48601c36",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Configurações e credenciais (opcional – para coleta por API)\n",
    "\n",
    "Preencha suas chaves em um arquivo `.env` ou defina variáveis de ambiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0327ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(SPOTIFY_CLIENT_ID='', SPOTIFY_CLIENT_SECRET='', GENIUS_TOKEN='', YT_API_KEY='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Spotify\n",
    "    SPOTIFY_CLIENT_ID: str = os.getenv('SPOTIFY_CLIENT_ID', '')\n",
    "    SPOTIFY_CLIENT_SECRET: str = os.getenv('SPOTIFY_CLIENT_SECRET', '')\n",
    "    # Genius\n",
    "    GENIUS_TOKEN: str = os.getenv('GENIUS_TOKEN', '')\n",
    "    # YouTube (opcional)\n",
    "    YT_API_KEY: str = os.getenv('YOUTUBE_API_KEY', '')\n",
    "\n",
    "cfg = Config()\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9926b55",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Ingestão de dados\n",
    "\n",
    "Você pode **(A)** carregar CSVs locais prontos (recomendado para rapidez e reprodutibilidade), ou **(B)** usar APIs (Spotify/Genius/YouTube) para coletar os dados.\n",
    "\n",
    "**Formato recomendado (CSV)**:  \n",
    "- `tracks.csv`: `track_id, artist, title, release_date, year, streams_30d, genre`\n",
    "- `audio_features.csv`: `track_id, danceability, energy, valence, tempo, key, mode`\n",
    "- `lyrics.csv`: `track_id, lyrics`\n",
    "\n",
    "> **Nota**: O Spotify Web API não fornece diretamente o *Top 200 Global* histórico. Você pode:  \n",
    "> - Usar dumps/CSVs públicos de paradas (quando disponíveis), ou  \n",
    "> - Utilizar *playlists* curadas como *Top 50 Global* em janelas temporais, ou  \n",
    "> - Definir sucesso por quantis de `streams_30d` na sua própria base consolidada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be88ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_csvs_or_raise(base_dir='data'):\n",
    "    base = Path(base_dir)\n",
    "    tracks_fp = base / 'tracks.csv'\n",
    "    feats_fp = base / 'audio_features.csv'\n",
    "    lyrics_fp = base / 'lyrics.csv'\n",
    "    if not all(p.exists() for p in [tracks_fp, feats_fp, lyrics_fp]):\n",
    "        raise FileNotFoundError('CSV(s) não encontrados. Use o caminho correto em base_dir ou gere dados sintéticos.')\n",
    "    tracks = pd.read_csv(tracks_fp)\n",
    "    feats = pd.read_csv(feats_fp)\n",
    "    lyrics = pd.read_csv(lyrics_fp)\n",
    "    return tracks, feats, lyrics\n",
    "\n",
    "# Exemplo de merge\n",
    "def build_dataset_from_csvs(tracks, feats, lyrics):\n",
    "    df = tracks.merge(feats, on='track_id', how='inner').merge(lyrics, on='track_id', how='left')\n",
    "    # Limpeza leve\n",
    "    df['year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year\n",
    "    df = df.dropna(subset=['streams_30d', 'danceability', 'energy', 'valence'])\n",
    "    df = df[df['genre'].str.lower().str.contains('pop', na=False)]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76c308",
   "metadata": {},
   "source": [
    "\n",
    "### 2.B. Coleta por API (esqueleto)\n",
    "\n",
    "Stubs com *placeholders* para você completar quando desejar. **Opcional**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a6a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Spotify (exemplo com spotipy) ---\n",
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# def spotify_client(cfg):\n",
    "#     auth = SpotifyClientCredentials(client_id=cfg.SPOTIFY_CLIENT_ID, client_secret=cfg.SPOTIFY_CLIENT_SECRET)\n",
    "#     return spotipy.Spotify(auth_manager=auth)\n",
    "\n",
    "# def fetch_audio_features(sp, track_ids):\n",
    "#     feats = []\n",
    "#     for i in range(0, len(track_ids), 50):\n",
    "#         chunk = track_ids[i:i+50]\n",
    "#         feats.extend(sp.audio_features(chunk))\n",
    "#     return pd.DataFrame(feats)\n",
    "\n",
    "# --- Genius (lyrics) ---\n",
    "# import lyricsgenius\n",
    "# def fetch_lyrics(genius_token, artist, title):\n",
    "#     genius = lyricsgenius.Genius(genius_token)\n",
    "#     song = genius.search_song(title, artist)\n",
    "#     return song.lyrics if song else None\n",
    "\n",
    "# --- YouTube (opcional) ---\n",
    "# from googleapiclient.discovery import build\n",
    "# def fetch_youtube_stats(api_key, query):\n",
    "#     yt = build('youtube', 'v3', developerKey=api_key)\n",
    "#     # ...\n",
    "#     return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88889acc",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Pré-processamento e features\n",
    "\n",
    "Inclui limpeza, deduplicação, cálculo de sentimento/lexical e geração do **alvo de sucesso** (quantil superior).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756936b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.nan\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    if not tokens:\n",
    "        return np.nan\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "def simple_sentiment(text):\n",
    "    # Placeholder: pontuação simplificada de sentimento (substitua por VADER/BERT conforme desejar)\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.nan\n",
    "    pos_words = {'love','good','happy','sun','party','dance','smile','together'}\n",
    "    neg_words = {'sad','bad','cry','alone','pain','dark'}\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    score = sum(1 for t in tokens if t in pos_words) - sum(1 for t in tokens if t in neg_words)\n",
    "    return score / max(1, len(tokens))\n",
    "\n",
    "def build_features(df, success_quantile=0.80):\n",
    "    df = df.copy()\n",
    "    # alvo binário de sucesso pelo quantil de streams_30d\n",
    "    threshold = df['streams_30d'].quantile(success_quantile)\n",
    "    df['success'] = (df['streams_30d'] >= threshold).astype(int)\n",
    "\n",
    "    # features textuais\n",
    "    df['lexical_diversity'] = df['lyrics'].apply(lexical_diversity)\n",
    "    df['sentiment_score']   = df['lyrics'].apply(simple_sentiment)\n",
    "\n",
    "    # harmonia/sonoridade (já disponíveis via Spotify audio_features)\n",
    "    # mode: 1 = maior, 0 = menor\n",
    "    df['mode_major'] = (df.get('mode', 1) == 1).astype(int)\n",
    "\n",
    "    # Seleção final de colunas (ajuste conforme necessário)\n",
    "    feature_cols = [\n",
    "        'danceability','energy','valence','tempo','mode_major',\n",
    "        'sentiment_score','lexical_diversity'\n",
    "    ]\n",
    "    df_model = df.dropna(subset=feature_cols + ['success']).copy()\n",
    "    return df_model, feature_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfa397",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Treino/validação e modelos\n",
    "\n",
    "Modelos: **Regressão Logística (baseline)** e **XGBoost** (ou **GradientBoosting** se XGBoost indisponível).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cd1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_eval(df_model, feature_cols):\n",
    "    X = df_model[feature_cols].values\n",
    "    y = df_model['success'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "    # Baseline\n",
    "    lr = LogisticRegression(max_iter=200, random_state=SEED)\n",
    "    lr.fit(X_train_s, y_train)\n",
    "    p_lr = lr.predict_proba(X_test_s)[:,1]\n",
    "    m_lr = {\n",
    "        'name': 'Regressão Logística (baseline)',\n",
    "        'auc': roc_auc_score(y_test, p_lr),\n",
    "        'f1': f1_score(y_test, (p_lr>=0.5).astype(int)),\n",
    "        'acc': accuracy_score(y_test, (p_lr>=0.5).astype(int)),\n",
    "        'prec': precision_score(y_test, (p_lr>=0.5).astype(int)),\n",
    "        'rec' : recall_score(y_test, (p_lr>=0.5).astype(int)),\n",
    "        'pr_auc': average_precision_score(y_test, p_lr),\n",
    "        'fpr_tpr': roc_curve(y_test, p_lr)[:2] + (roc_curve(y_test, p_lr)[2],),\n",
    "        'probas': p_lr,\n",
    "        'y_test': y_test,\n",
    "    }\n",
    "\n",
    "    # XGB ou GBT\n",
    "    if HAS_XGB:\n",
    "        mdl = XGBClassifier(\n",
    "            n_estimators=300, learning_rate=0.05, subsample=0.9,\n",
    "            max_depth=4, colsample_bytree=0.8, eval_metric='logloss',\n",
    "            random_state=SEED\n",
    "        )\n",
    "    else:\n",
    "        mdl = GradientBoostingClassifier(random_state=SEED)\n",
    "    mdl.fit(X_train_s, y_train)\n",
    "    p_m = mdl.predict_proba(X_test_s)[:,1] if hasattr(mdl, 'predict_proba') else mdl.decision_function(X_test_s)\n",
    "    p_m = (p_m - p_m.min())/(p_m.max()-p_m.min() + 1e-9)  # normaliza se preciso\n",
    "\n",
    "    m_g = {\n",
    "        'name': 'XGBoost' if HAS_XGB else 'GradientBoosting',\n",
    "        'auc': roc_auc_score(y_test, p_m),\n",
    "        'f1': f1_score(y_test, (p_m>=0.5).astype(int)),\n",
    "        'acc': accuracy_score(y_test, (p_m>=0.5).astype(int)),\n",
    "        'prec': precision_score(y_test, (p_m>=0.5).astype(int)),\n",
    "        'rec' : recall_score(y_test, (p_m>=0.5).astype(int)),\n",
    "        'pr_auc': average_precision_score(y_test, p_m),\n",
    "        'fpr_tpr': roc_curve(y_test, p_m)[:2] + (roc_curve(y_test, p_m)[2],),\n",
    "        'probas': p_m,\n",
    "        'y_test': y_test,\n",
    "        'model_obj': mdl\n",
    "    }\n",
    "\n",
    "    return [m_lr, m_g]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51162dbc",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Tabelas, correlações e figuras\n",
    "\n",
    "Gera as **Tabelas 1–3** e a **Figura 1 (ROC)** nos formatos prontos para colar no DOCX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def table1_characterization(df):\n",
    "    g = df.groupby('year').agg(\n",
    "        tracks=('track_id','nunique'),\n",
    "        artists=('artist','nunique'),\n",
    "        streams_mean=('streams_30d','mean'),\n",
    "        streams_median=('streams_30d','median')\n",
    "    ).reset_index().sort_values('year')\n",
    "    g.loc['Total'] = [\n",
    "        'Total',\n",
    "        g['tracks'].sum(),\n",
    "        g['artists'].sum(),\n",
    "        g['streams_mean'].mean(),\n",
    "        g['streams_median'].median()\n",
    "    ]\n",
    "    return g\n",
    "\n",
    "def table2_spearman(df_model, feature_cols):\n",
    "    # Spearman com pandas (sem p-valor)\n",
    "    rho = df_model[feature_cols + ['success']].corr(method='spearman')['success'].drop('success')\n",
    "    out = pd.DataFrame({'Variavel': rho.index, 'Spearman_rho': rho.values})\n",
    "    out['Direcao'] = np.where(out['Spearman_rho']>=0, 'Positiva', 'Negativa')\n",
    "    out['N'] = len(df_model)\n",
    "    return out\n",
    "\n",
    "def table3_metrics(models):\n",
    "    rows = []\n",
    "    for m in models:\n",
    "        rows.append([\n",
    "            m['name'], m['auc'], m['f1'], m['prec'], m['rec'], m['acc'], m['pr_auc']\n",
    "        ])\n",
    "    return pd.DataFrame(rows, columns=['Modelo','AUC-ROC','F1','Precisão','Revocação','Acurácia','PR-AUC'])\n",
    "\n",
    "def figure1_roc(models, out_png):\n",
    "    plt.figure()\n",
    "    for m in models:\n",
    "        fpr, tpr, _ = m['fpr_tpr']\n",
    "        plt.plot(fpr, tpr, label=m['name'])\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('Figura 1 – Curva ROC por modelo')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198484a",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Fluxo de execução com **dados sintéticos** (exemplo)\n",
    "\n",
    "Esta seção cria um conjunto de dados **fictício** apenas para validar o pipeline e gerar artefatos (tabelas/figuras).\n",
    "Substitua por seus dados reais nas seções anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddc43e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('exports/tabela1_caracterizacao.csv'),\n",
       " PosixPath('exports/tabela2_correlacoes.csv'),\n",
       " PosixPath('exports/tabela3_metricas.csv'),\n",
       " PosixPath('exports/figura1_roc.png'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def make_synthetic(n=1200, years=range(2020, 2025)):\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        for i in range(n//len(list(years))):\n",
    "            valence = rng.uniform(0,1)\n",
    "            energy = rng.uniform(0,1)\n",
    "            dance = rng.uniform(0,1)\n",
    "            mode = rng.integers(0,2)  # 1=maior\n",
    "            tempo = rng.normal(120, 20)\n",
    "            sentiment = (valence - 0.5) * 0.3 + rng.normal(0, 0.02)\n",
    "            lexdiv = rng.uniform(0.2, 0.6)\n",
    "            # streams correlaciona com algumas features\n",
    "            log_streams = (\n",
    "                10\n",
    "                + 1.2*valence\n",
    "                + 0.8*dance\n",
    "                + 0.5*energy\n",
    "                + 0.3*mode\n",
    "                + 0.6*sentiment\n",
    "                + rng.normal(0, 0.7)\n",
    "            )\n",
    "            streams = np.exp(log_streams)  # positivo\n",
    "            rows.append({\n",
    "                'track_id': f'{y}_{i}',\n",
    "                'artist': f'Artist_{rng.integers(1,300)}',\n",
    "                'title':  f'Track_{i}',\n",
    "                'release_date': f'{y}-01-01',\n",
    "                'year': y,\n",
    "                'streams_30d': streams,\n",
    "                'genre': 'Pop',\n",
    "                'danceability': dance,\n",
    "                'energy': energy,\n",
    "                'valence': valence,\n",
    "                'tempo': tempo,\n",
    "                'mode': mode,\n",
    "                'lyrics': 'We love to dance and smile together under the sun'\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# Gera dataset sintético e aplica o pipeline completo\n",
    "df_syn = make_synthetic()\n",
    "df_model, feature_cols = build_features(df_syn, success_quantile=0.80)\n",
    "models = train_and_eval(df_model, feature_cols)\n",
    "\n",
    "t1 = table1_characterization(df_syn)\n",
    "t2 = table2_spearman(df_model, feature_cols)\n",
    "t3 = table3_metrics(models)\n",
    "\n",
    "# Exporta artefatos\n",
    "t1_fp = EXPORT_DIR / 'tabela1_caracterizacao.csv'\n",
    "t2_fp = EXPORT_DIR / 'tabela2_correlacoes.csv'\n",
    "t3_fp = EXPORT_DIR / 'tabela3_metricas.csv'\n",
    "fig1_fp = EXPORT_DIR / 'figura1_roc.png'\n",
    "\n",
    "t1.to_csv(t1_fp, index=False)\n",
    "t2.to_csv(t2_fp, index=False)\n",
    "t3.to_csv(t3_fp, index=False)\n",
    "figure1_roc(models, str(fig1_fp))\n",
    "\n",
    "t1_fp, t2_fp, t3_fp, fig1_fp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b6f90",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Execução com **dados reais (CSV)**\n",
    "\n",
    "Quando você tiver os CSVs, a execução típica será:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a801199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tracks, feats, lyrics = load_csvs_or_raise(base_dir='data')\n",
    "# df = build_dataset_from_csvs(tracks, feats, lyrics)\n",
    "# df_model, feature_cols = build_features(df, success_quantile=0.80)\n",
    "# models = train_and_eval(df_model, feature_cols)\n",
    "\n",
    "# # Tabelas e figura\n",
    "# t1 = table1_characterization(df)\n",
    "# t2 = table2_spearman(df_model, feature_cols)\n",
    "# t3 = table3_metrics(models)\n",
    "# t1.to_csv(EXPORT_DIR/'tabela1_caracterizacao.csv', index=False)\n",
    "# t2.to_csv(EXPORT_DIR/'tabela2_correlacoes.csv', index=False)\n",
    "# t3.to_csv(EXPORT_DIR/'tabela3_metricas.csv', index=False)\n",
    "# figure1_roc(models, str(EXPORT_DIR/'figura1_roc.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07974653",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Logs de reprodutibilidade\n",
    "\n",
    "Versões de pacotes e *seed*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efa0b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0]\n",
      "Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "sklearn: 1.7.1\n",
      "pandas: 2.3.2\n",
      "numpy: 2.2.6\n",
      "matplotlib: 3.10.6\n",
      "SEED: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, platform\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "import sklearn, pandas, numpy, matplotlib\n",
    "print('sklearn:', sklearn.__version__)\n",
    "print('pandas:', pandas.__version__)\n",
    "print('numpy:', numpy.__version__)\n",
    "print('matplotlib:', matplotlib.__version__)\n",
    "print('SEED:', SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b1f7f44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/util/retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/util/util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de coleta de dados da web (opcional)\u001b[39;00m\n\u001b[32m      3\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://pro-musicabr.org.br/home/top-50-streaming/index.php?top50sPeriodo=04/2024\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m response.raise_for_status()\n\u001b[32m      7\u001b[39m soup = BeautifulSoup(response.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/tcc/spotify-br-2024-lyrics-harmony-analysis-tcc/.venv/lib/python3.12/site-packages/requests/adapters.py:659\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    644\u001b[39m     resp = conn.urlopen(\n\u001b[32m    645\u001b[39m         method=request.method,\n\u001b[32m    646\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    655\u001b[39m         chunked=chunked,\n\u001b[32m    656\u001b[39m     )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    663\u001b[39m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "# Exemplo de coleta de dados da web (opcional)\n",
    "\n",
    "url = \"https://pro-musicabr.org.br/home/top-50-streaming/index.php?top50sPeriodo=04/2024\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Exibe o título da página\n",
    "print(\"Título da página:\", soup.title.string.strip())\n",
    "\n",
    "# Procura a primeira tabela relevante e exibe como DataFrame\n",
    "tables = soup.find_all(\"table\")\n",
    "if tables:\n",
    "    df = pd.read_html(str(tables[0]))[0]\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Nenhuma tabela encontrada na página.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
